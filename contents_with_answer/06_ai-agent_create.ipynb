{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08a3ea53-599c-46bc-8804-812bf8492604",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# LangGraph custom schema agent notebook\n",
    "\n",
    "This notebook shows you how to write a LangGraph AI agent compatible with Mosaic AI Agent Framework that accepts custom inputs and returns custom outputs. \n",
    "\n",
    "To ensure compatibility, the agent must conform to Mosaic AI Agent Framework schema requirements, see ([AWS](https://docs.databricks.com/en/generative-ai/agent-framework/agent-schema.html) | [Azure](https://learn.microsoft.com/en-us/azure/databricks/generative-ai/agent-framework/agent-schema)).\n",
    "\n",
    "### Model-as-code notebook\n",
    "\n",
    "Mosaic AI Agent Framework uses MLflow's **Models-as-code** development workflow, which requires two notebooks: \n",
    "\n",
    "- An agent notebook that defines the agent's logic (this notebook)\n",
    "- A driver notebook that logs, registers, and deploys the agent\n",
    "  - You can find the driver notebook for this agent, **custom-langgraph-schema-driver**, on Databricks documentation ([AWS](https://docs.databricks.com/en/generative-ai/agent-framework/agent-schema.html#langgraph-custom-schema-driver-notebook) | [Azure](https://learn.microsoft.com/en-us/azure/databricks/generative-ai/agent-framework/agent-schema#langgraph-custom-schema-driver-notebook))\n",
    "\n",
    "For more information on Model-as-code, see MLflow's [Models as code guide](https://mlflow.org/docs/latest/model/models-from-code.html).\n",
    "\n",
    "## Requirements\n",
    "\n",
    "This notebook requires a Unity Catalog enabled workspace.\n",
    "\n",
    " **_NOTE:_**  This notebook uses LangGraph, but Mosaic AI Agent Framework is compatible with other agent authoring frameworks, like LlamaIndex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dcf9b653-429c-4281-8fcf-cf566367989f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %pip install -U -qqqq mlflow>=2.19.0 langchain==0.2.16 langgraph-checkpoint==1.0.12 langchain_core langgraph==0.2.16 pydantic databricks-langchain\n",
    "\n",
    "# %pip install -U -qqqq mlflow langchain==0.2.16 langgraph-checkpoint==1.0.12 langchain_core langgraph==0.2.16 pydantic databricks-langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf89a91f-5330-4d6c-853a-61a2ccf70dea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U mlflow langchain langgraph-checkpoint langchain_core langgraph pydantic databricks-langchain\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "013051e5-0a10-4388-a6ff-b0e05f2ff9ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Define the chat model\n",
    "Create a LangGraph chat model that supports [LangGraph tool](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/) calling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b445eef-9653-4df8-a07b-b654ef70a987",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "# from databricks_langchain import VectorSearchRetrieverTool, ChatDatabricks\n",
    "from databricks_langchain import ChatDatabricks\n",
    "\n",
    "mlflow.langchain.autolog()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42026687-eac4-4ffc-ae8b-1c0847d2ec67",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Parse LangGraph output\n",
    "\n",
    "The following cell defines helper methods for converting LangGraph output messages into the recommended output schema for Mosaic AI agent framework. The `wrap_output` helper returns chat-completion compatible messages, with an additional `custom_outputs` field containing custom outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7543f731-2188-4932-81e8-9d37cd1cb8f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from typing import Iterator, Dict, Any\n",
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    ToolMessage,\n",
    "    MessageLikeRepresentation,\n",
    ")\n",
    "from mlflow.types.llm import ChatCompletionRequest, ChatCompletionResponse, ChatChoice, ChatMessage\n",
    "from random import randint\n",
    "from dataclasses import asdict\n",
    "import logging\n",
    "\n",
    "import json\n",
    "\n",
    "# You can add additional fields to the return object below\n",
    "def create_flexible_chat_completion_response(content: str, id: int = 0) -> Dict:\n",
    "    return asdict(ChatCompletionResponse(\n",
    "        choices=[ChatChoice(message=ChatMessage(role=\"assistant\", content=content))],\n",
    "        custom_outputs={\n",
    "            \"id\": id\n",
    "        },\n",
    "    ))\n",
    "\n",
    "def wrap_output(stream: Iterator[MessageLikeRepresentation]) -> Iterator[Dict]:\n",
    "    \"\"\"\n",
    "    Process and yield formatted outputs from the message stream.\n",
    "    The invoke and stream langchain functions produce different output formats.\n",
    "    This function handles both cases.\n",
    "    \"\"\"\n",
    "    for event in stream:\n",
    "        # the agent was called with invoke()\n",
    "        if \"messages\" in event:\n",
    "            output_content = \"\"\n",
    "            for msg in event[\"messages\"]:\n",
    "                output_content += msg.content\n",
    "            # Note: you can pass additional fields from your LangGraph nodes to the output here\n",
    "            yield create_flexible_chat_completion_response(content=output_content, id=randint(100000000, 10000000000))\n",
    "        # the agent was called with stream()\n",
    "        else:\n",
    "            for node in event:\n",
    "                for key, messages in event[node].items():\n",
    "                    if isinstance(messages, list):\n",
    "                        for msg in messages:\n",
    "                            # Note: you can pass additional fields from your LangGraph nodes to the output here\n",
    "                            yield create_flexible_chat_completion_response(content=msg.content, id=randint(100000000, 10000000000))\n",
    "                    else:\n",
    "                        logging.warning(f\"Unexpected value {messages} for key {key}. Expected a list of `MessageLikeRepresentation`'s\")\n",
    "                        yield create_flexible_chat_completion_response(content=str(messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df9f5ad3-d7eb-49ee-b37d-5bfa51aab163",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Create the agent\n",
    "Use the LangGraph [`create_react_agent` function](https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/#usage) to build a simple graph. For more customization, you can create your own LangGraph agent by following [LangGraph - Quick Start](https://langchain-ai.github.io/langgraph/tutorials/introduction/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8fe7ea85-4fb0-42ba-b05f-61f4b6a9d074",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Databricks Vector Srarchを利用したRAGのretrieve\n",
    "\n",
    "DatabricksVectorSearch のインスタンスを作成  \n",
    "[参考URL](https://python.langchain.com/docs/integrations/vectorstores/databricks_vector_search/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6c4f2b0-9973-410d-9ac1-2376bafe310a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE FUNCTION trainer_catalog.05_vector_search_index_for_nssol.product_docs_vector_search (\n",
    "  -- The agent uses this comment to determine how to generate the query string parameter.\n",
    "  query STRING\n",
    "  COMMENT 'The query string for searching our product documentation.'\n",
    ") RETURNS TABLE\n",
    "-- The agent uses this comment to determine when to call this tool. It describes the types of documents and information contained within the index.\n",
    "COMMENT 'Executes a search on product documentation to retrieve text documents most relevant to the input query.' RETURN\n",
    "SELECT\n",
    "  id as id,\n",
    "  map('url', url, 'content', content) as metadata\n",
    "FROM\n",
    "  vector_search(\n",
    "    -- Specify your Vector Search index name here\n",
    "    index => 'trainer_catalog.05_vector_search_index_for_nssol.product_documentation_vs_index',\n",
    "    query => query,\n",
    "    num_results => 5\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89cd8e09-fc8e-42e7-a736-06a53be31847",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# vs_tool = VectorSearchRetrieverTool(\n",
    "#     # endpoint=\"vs_endpoint\",\n",
    "#     index_name=\"trainer_catalog.05_vector_search_index_for_nssol.product_documentation_vs_index\",\n",
    "#     tool_name=\"product_docs_retriever\",\n",
    "#     tool_description=\"Retrieves information about our products from official documentation.\"\n",
    "# )\n",
    "\n",
    "# Run a query against the vector search index locally for testing\n",
    "# vs_tool.invoke(\"修理の手順は?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73f85a83-66b2-4d1e-bfcc-7ec2cf43fbc9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### AI Functionの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d8ea7da-d5fe-4fd6-9171-0390652713e6",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "AI Functionの作成"
    }
   },
   "outputs": [],
   "source": [
    "func_name = [\n",
    "    \"trainer_catalog.03_data_analysis_by_gen_ai_for_nssol.product_with_many_inquiries\",\n",
    "    \"trainer_catalog.05_vector_search_index_for_nssol.product_docs_vector_search\"\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77d923d6-82ce-4d48-a342-589582056579",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from unitycatalog.ai.langchain.toolkit import UCFunctionToolkit\n",
    "from unitycatalog.ai.core.databricks import DatabricksFunctionClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5fc770d1-dfe8-4b92-a497-509d61cc8570",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Databricks Function クライアントの作成\n",
    "client = DatabricksFunctionClient()\n",
    "\n",
    "# UCFunctionToolkit を利用して、Unity Catalog 関数をツールとして登録\n",
    "toolkit = UCFunctionToolkit(\n",
    "    function_names=func_name,\n",
    "    client=client\n",
    ")\n",
    "\n",
    "tools = toolkit.tools\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4fd12be3-1d37-4e3c-a8db-be6a58a340df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# tools = [tool,vs_tool]\n",
    "tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "339ea442-46b1-4abc-afe6-484f27c6fddc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Agent作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b603f0fa-006b-42a5-b3b2-0155e84d6976",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "# from langchain_anthropic import ChatAnthropic\n",
    "# from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "# tool = TavilySearchResults(max_results=2)\n",
    "# tools = [tool]\n",
    "llm = ChatDatabricks(endpoint=\"openhack-gpt-4o\")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=tools)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "# Any time a tool is called, we return to the chatbot to decide the next step\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "774a81d1-250c-44f0-b164-6f89b29fab64",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "グラフを見てみる"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd82e527-deaf-4214-a4ba-f06290e1619c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def stream_graph_updates(user_input: str):\n",
    "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f32cb2db-e8ae-45f6-882a-7ba15ae53cb5",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "ノートブック上でのテスト"
    }
   },
   "outputs": [],
   "source": [
    "# while True:\n",
    "#     try:\n",
    "#         user_input = input(\"User: \")\n",
    "#         if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "#             print(\"Goodbye!\")\n",
    "#             break\n",
    "\n",
    "#         stream_graph_updates(user_input)\n",
    "#     except:\n",
    "#         # fallback if input() is not available\n",
    "#         user_input = \"What do you know about LangGraph?\"\n",
    "#         print(\"User: \" + user_input)\n",
    "#         stream_graph_updates(user_input)\n",
    "#         break\n",
    "\n",
    "# 質問例：問い合わせの多い製品の修理手順を教えてください\n",
    "# \"quit\", \"exit\", \"q\" で終了させてください"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "127b98b1-d0d3-4bc6-8e4a-602372b71b60",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# ここまで"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d31eb88-232d-4394-a07b-50395c513761",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableGenerator\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# Create the agent with the system message if it exists\n",
    "agent_with_raw_output = create_react_agent(llm_with_tools, tools)\n",
    "\n",
    "agent = agent_with_raw_output| RunnableGenerator(wrap_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbab1a0f-8f56-42dd-9628-b2b36c43f5e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Test the agent\n",
    "\n",
    "Interact with the agent to test its output. Since this notebook called `mlflow.langchain.autolog()` you can view the trace for each step the agent takes.\n",
    "\n",
    "Replace this placeholder input with an appropriate domain-specific example for your agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f803b4c-9269-4fde-a20c-248c5d6f1b08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TODO: replace this placeholder input example with an appropriate domain-specific example for your agent\n",
    "input_messages = [ChatMessage(role=\"user\", content=\"問い合わせの多い製品の修理手順を教えてください\")]\n",
    "input_example = asdict(ChatCompletionRequest(messages=input_messages))\n",
    "\n",
    "for event in agent.stream(input_example):\n",
    "    print(event, \"---\" * 20 + \"\\n\")\n",
    "# for event in agent(input_example):\n",
    "#     print(event, \"---\" * 20 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ffb18c51-2a98-420c-a73a-94e7fc2a0313",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.models.set_model(agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7866ff3b-8486-4e9d-9ca9-6f61ad638433",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Next steps\n",
    "\n",
    "You can rerun the cells above to iterate and test the agent.\n",
    "\n",
    "See the driver notebook, **custom-langgraph-schema-driver** ([AWS](https://docs.databricks.com/en/generative-ai/agent-framework/agent-schema.html#langchain-custom-schema-driver-notebook) | [Azure](https://learn.microsoft.com/en-us/azure/databricks/generative-ai/agent-framework/agent-schema#langchain-custom-schemas)), to learn how to log, register, and deploy this agent."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6179022356775914,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "06_ai-agent_create",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
